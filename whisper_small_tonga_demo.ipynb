{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1gW5i_oRlg65ZQe9dd9Ujj2Y1cbFAJu_j",
      "authorship_tag": "ABX9TyN84C+GQxFV+1PguuYAwNGo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kalindasiaminwe/NLP_and_ML_Projects/blob/master/whisper_small_tonga_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TongaSpeechASR\n",
        "\n",
        "This is prototypical model for demo purposes only. This prototype application is designed to showcase the capabilities of our state-of-the-art automatic speech recognition technology. \n",
        "\n",
        "Use the link shown on \"Running on public URL:\" to open the demo in a new tab"
      ],
      "metadata": {
        "id": "BOJnYwrkAmQg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** If your microphone is recording silent recordings, the output will be blank. In such a case, record your Tonga phrase using another recorder that saves the audio in Waveform Audio File Format(.wav) or MP3 coding format and upload the audio file to have it transcribed."
      ],
      "metadata": {
        "id": "_1Cpw4v5C5Qf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n",
        "!pip install transformers\n",
        "import torch"
      ],
      "metadata": {
        "id": "sm5Q5ohosh3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gradio as gr\n",
        "from transformers import pipeline\n",
        "\n",
        "\n",
        "MODEL_NAME = \"kalisia/whisper-small-tonga_5hrs\"\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "pipe = pipeline(\n",
        "    task=\"automatic-speech-recognition\",\n",
        "    model=MODEL_NAME,\n",
        "    chunk_length_s=30,\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "\n",
        "def transcribe(microphone, file_upload):\n",
        "    warn_output = \"\"\n",
        "    if (microphone is not None) and (file_upload is not None):\n",
        "        warn_output = (\n",
        "            \"WARNING: You've uploaded an audio file and used the microphone. \"\n",
        "            \"The recorded file from the microphone will be used and the uploaded audio will be discarded.\\n\"\n",
        "        )\n",
        "\n",
        "    elif (microphone is None) and (file_upload is None):\n",
        "        return \"ERROR: You have to either use the microphone or upload an audio file\"\n",
        "\n",
        "    file = microphone if microphone is not None else file_upload\n",
        "\n",
        "    text = pipe(file)[\"text\"]\n",
        "\n",
        "    return warn_output + text\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "transcribe = gr.Interface(\n",
        "    fn=transcribe,\n",
        "    inputs=[\n",
        "        gr.inputs.Audio(source=\"microphone\", type=\"filepath\", optional=True),\n",
        "        gr.inputs.Audio(source=\"upload\", type=\"filepath\", optional=True),\n",
        "    ],\n",
        "    outputs=\"text\",\n",
        "    layout=\"horizontal\",\n",
        "    theme=\"huggingface\",\n",
        "    title=\"Whisper Demo: Transcribe Audio\",\n",
        "    description=(\n",
        "        \"Transcribe audio inputs with the click of a button! Demo uses the the fine-tuned\"\n",
        "        f\" checkpoint [{MODEL_NAME}](https://huggingface.co/{MODEL_NAME}) and ðŸ¤— Transformers to transcribe audio files\"\n",
        "        \n",
        "    ),\n",
        "    allow_flagging=\"never\",\n",
        "     examples = [[\"/content/drive/MyDrive/save_dir/Default_20221210-144448.mp3\"], [\"/content/drive/MyDrive/Tonga/data/audio/220824-212101_toi_0ae_elicit_17.wav\"], [\"/content/drive/MyDrive/Tonga/data/audio/220903-202609_toi_707_elicit_7.wav\"]],\n",
        ")\n",
        "\n",
        "transcribe.launch(share=True)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 750
        },
        "id": "PbAN99hN_Zv_",
        "outputId": "4bd23866-0a66-4385-aea0-b6b7727f911e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gradio/inputs.py:318: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.8/dist-packages/gradio/deprecation.py:40: UserWarning: `layout` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.8/dist-packages/gradio/interface.py:332: UserWarning: Currently, only the 'default' theme is supported.\n",
            "  warnings.warn(\"Currently, only the 'default' theme is supported.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "Running on public URL: https://c169d5cf04633bda.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c169d5cf04633bda.gradio.app\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QAwHZeJ5AUww"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}